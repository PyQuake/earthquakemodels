finalData = merge(finalData, data, all.y=T)
}
else{
finalData=rbind(finalData, data)
}
rm(data)
}
save(finalData,file="../DataFromR/newdata.Rda")
summary(finalData)
# which(finalData$model=='GAModel')
# which(finalData$model=='ReducedGAModel')
# which(finalData$model=='EMP-GAModel')
# which(finalData$model=='EMP-ReducedGAModel')
# which(finalData$model=='GAModel')
# which(finalData$model=='ReducedGAModel')
#
#
setwd("~/Documents/estudos/unb/earthquakemodels/code/")
chooseRegion = function(i){
if (i==1) {
region="Kanto"
}
else if (i==2) {
region="Kansai"
}
else if (i==3) {
region = "Tohoku"
}
else{
region = "EastJapan"
}
return(region)
}
loadData = function(type, region, year, depth){
file = paste('loglike/',type,region,'_',depth,'_',year,".txt",sep="")
data = read.csv2(file, sep='\n', header=F)
return(data)
}
region = chooseRegion(1)
for (year in 2005:2008){
#gamodelpar
gaModelPar100 = loadData('parallel-random', region, year, '100')
valuesGAPar100 = convertToNumeric(gaModelPar100)
loglikeValues = c(valuesGAPar100)
nameGa = c(rep("GAModelPar",10))
years = c(rep(toString(year),10))
regions = c(rep(region, 10))
depth100 = c(rep('100',10))
depthsAmodel = c(depth100)
model = c(nameGa)
depths = c(depthsAmodel, depthsAmodel)
data = data.frame(loglikeValues, model,depths, years, regions)
finalData=rbind(finalData, data)
rm(data)
#parallelList
gaModelPar100 = loadData('parallelList-random', region, year, '100')
valuesGAPar100 = convertToNumeric(gaModelPar100)
loglikeValues = c(valuesGAPar100)
nameGa = c(rep("ReducedGAModelPar",10))
years = c(rep(toString(year),10))
regions = c(rep(region, 10))
depth100 = c(rep('100',10))
depthsAmodel = c(depth100)
model = c(nameGa)
depths = c(depthsAmodel, depthsAmodel)
data = data.frame(loglikeValues, model,depths, years, regions)
finalData=rbind(finalData, data)
rm(data)
#sc-parallel-random
gaModelPar100 = loadData('sc-parallel-random', region, year, '100')
valuesGAPar100 = convertToNumeric(gaModelPar100)
loglikeValues = c(valuesGAPar100)
nameGa = c(rep("GAModelParSC",10))
years = c(rep(toString(year),10))
regions = c(rep(region, 10))
depth100 = c(rep('100',10))
depthsAmodel = c(depth100)
model = c(nameGa)
depths = c(depthsAmodel, depthsAmodel)
data = data.frame(loglikeValues, model,depths, years, regions)
finalData=rbind(finalData, data)
rm(data)
#sc-parallelList-
gaModelPar100 = loadData('sc-parallelList-random', region, year, '100')
valuesGAPar100 = convertToNumeric(gaModelPar100)
loglikeValues = c(valuesGAPar100)
nameGa = c(rep("ReducedGAModelParSC",10))
years = c(rep(toString(year),10))
regions = c(rep(region, 10))
depth100 = c(rep('100',10))
depthsAmodel = c(depth100)
model = c(nameGa)
depths = c(depthsAmodel, depthsAmodel)
data = data.frame(loglikeValues, model,depths, years, regions)
finalData=rbind(finalData, data)
rm(data)
}
summary(finalData)
subTabela = finalData[finalData$regions=='Kanto',]
subTabela = subTabela[subTabela$years!='2009'&subTabela$years!='2010',]
summary(subTabela)
subTabela = subTabela[subTabela$model!='Emp-GAModel'&subTabela$model!='Emp-ReducedGAModel'&
subTabela$model!='Emp-GAModelWindow'&subTabela$model!='Emp-ReducedGAModelWindow',]
summary(subTabela)
subTabela = finalData[finalData$regions=='Kanto',]
subTabela = subTabela[subTabela$years!='2009'&subTabela$years!='2010',]
summary(subTabela)
finalData$loglikeValues[finalData$model=='ReducedGAModelParSC']
finalData$loglikeValues[finalData$model=='ReducedGAModelParSC'&finalData$year=='2005', ]
finalData$loglikeValues[finalData$model=='ReducedGAModelParSC'&finalData$year=='2005']
finalData$loglikeValues[finalData$model=='ReducedGAModelParSC'&finalData$year=='2005']
mean(finalData$loglikeValues[finalData$model=='ReducedGAModelParSC'&finalData$year=='2005'])
mean(finalData$loglikeValues[finalData$model=='GAModelPar'&finalData$year=='2005'])
mean(finalData$loglikeValues[finalData$model=='ReducedGAModelPar'&finalData$year=='2005'])
mean(finalData$loglikeValues[finalData$model=='GAModelParSC'&finalData$year=='2005'])
mean(finalData$loglikeValues[finalData$model=='ReducedGAModelParSC'&finalData$year=='2005'])
mean(finalData$loglikeValues[finalData$model=='GAModelPar'&finalData$year=='2006'])
mean(finalData$loglikeValues[finalData$model=='ReducedGAModelPar'&finalData$year=='2006'])
mean(finalData$loglikeValues[finalData$model=='GAModelParSC'&finalData$year=='2006'])
mean(finalData$loglikeValues[finalData$model=='ReducedGAModelParSC'&finalData$year=='2006'])
mean(finalData$loglikeValues[finalData$model=='GAModelPar'&finalData$year=='2007'])
mean(finalData$loglikeValues[finalData$model=='ReducedGAModelPar'&finalData$year=='2007'])
mean(finalData$loglikeValues[finalData$model=='GAModelParSC'&finalData$year=='2007'])
mean(finalData$loglikeValues[finalData$model=='ReducedGAModelParSC'&finalData$year=='2007'])
mean(finalData$loglikeValues[finalData$model=='GAModelPar'&finalData$year=='2008'])
mean(finalData$loglikeValues[finalData$model=='ReducedGAModelPar'&finalData$year=='2008'])
mean(finalData$loglikeValues[finalData$model=='GAModelParSC'&finalData$year=='2008'])
mean(finalData$loglikeValues[finalData$model=='ReducedGAModelParSC'&finalData$year=='2008'])
plotModelsByYears= function('parallelList-random', depth)
loadData = function(type, region, year, depth){
file = paste('loglike/',type,region,'_',depth,'_',year,".txt",sep="")
data = read.csv2(file, sep='\n', header=F)
return(data)
}
calcMedia = function(type, year, depth, region,r,c){
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,region,'_',depth,'_',year,i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
plotMatrixModel = function(modelData, fileToSave, r, c){
# TODO -- hardcoded map is BAD
matrixData = matrix(nrow = r, ncol = c)
k = 1
for (i in 1:r){
for (j in 1:c){
if(is.na(modelData[k])==T){
value=0
}
else{
value = modelData[k]
if (value > 12){
value = 12
}
}
matrixData[i,j] = value
k = k + 1
}
}
png(fileToSave, width = 800, height = 800)
jBrewColors <- rev(heat.colors(16))
p = levelplot((matrixData), col.regions = jBrewColors, alpha.regions=0.6)
grid.raster(as.raster(readPNG(imagePath)))
print( p+ layer(grid.raster(as.raster(readPNG(imagePath))), under=T))
dev.off()
}
plotModelsByYears= function(type, depth){
year=2005
#modelo
while(year<=2010){
region="Kanto"
saveFile = paste("./heatMap/",depth,region,"_",depth,'_',year,".png",sep="")
mediaKanto=calcMedia(type=type,year=year, region=region, depth=depth, 45,45)
imagePath<<-"../../data/kantomap.png"
plotMatrixModel(mediaKanto, saveFile, 45, 45)
year=year+1
}
}
plotModelsByYears= ('parallelList-random', depth)
plotModelsByYears= function(type, depth){
year=2005
#modelo
while(year<=2010){
region="Kanto"
saveFile = paste("./heatMap/",depth,region,"_",depth,'_',year,".png",sep="")
mediaKanto=calcMedia(type=type,year=year, region=region, depth=depth, 45,45)
imagePath<<-"../../data/kantomap.png"
plotMatrixModel(mediaKanto, saveFile, 45, 45)
year=year+1
}
}
plotModelsByYears('parallelList-random', depth)
saveFile = paste("./heatMap/",depth,region,"_",depth,'_',year,".png",sep="")
year
depth
depth=100
depth
saveFile = paste("./heatMap/",region,"_",depth,'_',year,".png",sep="")
plotModelsByYears= function(type, depth){
year=2005
#modelo
while(year<=2010){
region="Kanto"
saveFile = paste("./heatMap/",region,"_",depth,'_',year,".png",sep="")
mediaKanto=calcMedia(type=type,year=year, region=region, depth=depth, 45,45)
imagePath<<-"../../data/kantomap.png"
plotMatrixModel(mediaKanto, saveFile, 45, 45)
year=year+1
}
}
plotModelsByYears('parallelList-random', depth)
calcMedia = function(type, year, depth, region,r,c){
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/',region,'_',depth,'_',year,i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
plotModelsByYears('parallelList-random', depth)
imagePath<<-"../data/kantomap.png"
plotModelsByYears= function(type, depth){
year=2005
#modelo
while(year<=2010){
region="Kanto"
saveFile = paste("./heatMap/",region,"_",depth,'_',year,".png",sep="")
mediaKanto=calcMedia(type=type,year=year, region=region, depth=depth, 45,45)
imagePath<<-"../data/kantomap.png"
plotMatrixModel(mediaKanto, saveFile, 45, 45)
year=year+1
}
}
plotModelsByYears('parallelList-random', depth)
plotModelsByYears('parallel-random', depth)
plotModelsByYears('sc-parallel-random', depth)
plotModelsByYears('sc-parallelList-random', depth)
plotModelsByYears('parallelList-random', depth)
plotModelsByYears= function(type, depth){
year=2005
#modelo
while(year<=2008){
region="Kanto"
saveFile = paste("./heatMap/",type,region,"_",depth,'_',year,".png",sep="")
mediaKanto=calcMedia(type=type,year=year, region=region, depth=depth, 45,45)
imagePath<<-"../data/kantomap.png"
plotMatrixModel(mediaKanto, saveFile, 45, 45)
year=year+1
}
}
plotModelsByYears('parallel-random', depth)
plotModelsByYears('sc-parallel-random', depth)
plotModelsByYears('sc-parallelList-random', depth)
plotModelsByYears('parallelList-random', depth)
calcMedia = function(type, year, depth, region,r,c){
if (type=='hybrid_ListaGA_New') {
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/hybrid_ListaGA_New',region,'_',depth,'_',year,'_',i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if(type=='hybrid_gaModel'){
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/hybrid_gaModel',region,'_',depth,'_',year,'_',i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='clusteredII_gaModel') {
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/',region,'_',depth,'_',year,i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='clusteredII_hybrid_gaModel') {
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/hybrid_gaModel',region,'_',depth,'_',year,'_',i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='clusteredII_hybrid_ListaGA_New') {
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/hybrid_listaGA_New',region,'_',depth,'_',year,'_',i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='clusteredII_listaGA_new') {
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/',region,'_',depth,'_',year,i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='clustered_gaModel') {
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/',region,'_',depth,'_',year,i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='clustered_hybrid_gaModel') {
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/hybrid_gaModel',region,'_',depth,'_',year,'_',i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='clustered_hybrid_ListaGA_New') {
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/hybrid_ListaGA_New',region,'_',depth,'_',year,'_',i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='clustered_listaGA_new') {
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/',region,'_',depth,'_',year,i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
#       sc_hybrid_ListaGA_New
#       sc_hybrid_gaModel
#       scModel
else if (type=='sc_hybrid_ListaGA_New'){
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/hybrid_ListaGA_New',region,'_',depth,'_',year,'_',i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='sc_hybrid_gaModel'){
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/hybrid_gaModel',region,'_',depth,'_',year,'_',i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='listgamodel'){
soma = rep(0, r*c)
for(i in 1:10){
if (region== 'EastJapan'){
file = paste('../Zona3/scModel/eastgamodel',region,'_',depth,'_',year,i-1,".txt",sep="")
}
else{
file = paste( '../Zona3/scModel/listgamodel',region,'_',depth,'_',year,i-1,".txt",sep="")
}
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else if (type=='gaModel'){
soma = rep(0, r*c)
for(i in 1:10){
file = paste('../Zona3/scModel/gamodel',region,'_',depth,'_',year,i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
else{
soma = rep(0, r*c)
for(i in 1:10){
file = paste(type,'/',region,'_',depth,'_',year,i-1,".txt",sep="")
raw_data = read.csv2(file, sep='\n', header=F)
for (k in 1:length(raw_data$V1)){
value = as.numeric(levels(raw_data$V1[k]))[raw_data$V1[k]]
soma[k]=soma[k]+value
}
}
return(soma/10)
}
}
plotMatrixModel = function(modelData, fileToSave, r, c){
# TODO -- hardcoded map is BAD
matrixData = matrix(nrow = r, ncol = c)
k = 1
for (i in 1:r){
for (j in 1:c){
if(is.na(modelData[k])==T){
value=0
}
else{
value = modelData[k]
if (value > 12){
value = 12
}
}
matrixData[i,j] = value
k = k + 1
}
}
png(fileToSave, width = 800, height = 800)
jBrewColors <- rev(heat.colors(16))
# imageData=grid.raster(as.raster(readPNG("../data/touhoku.png")))
p = levelplot((matrixData), col.regions = jBrewColors, alpha.regions=0.6)
grid.raster(as.raster(readPNG(imagePath)))
print( p+ layer(grid.raster(as.raster(readPNG(imagePath))), under=T))
dev.off()
}
plotModelsByYears= function(type, depth){
year=2005
#modelo
while(year<=2010){
setwd("~/Documents/estudos/unb/earthquakemodels/Zona2/")
region="EastJapan"
saveFile = paste("./heatMap/",depth,'/',type,region,"_",depth,'_',year,".png",sep="")
mediaEastJapan=calcMedia(type=type,year=year, region=region, depth=depth, 40,40)
imagePath<<-"../data/coast.png"
plotMatrixModel(mediaEastJapan, saveFile, 40, 40)
#20X40!
# a imagem tÃ¡ uma merda
region="Tohoku"
saveFile = paste("./heatMap/",depth,'/',type,region,"_",depth,'_',year,".png",sep="")
mediaTouhoku=calcMedia(type=type,year=year, region=region, depth=depth, 20,40)
imagePath<<-"../data/touhoku.png"
plotMatrixModel(mediaTouhoku, saveFile, 20, 40)
region="Kansai"
saveFile = paste("./heatMap/",depth,'/',type,region,"_",depth,'_',year,".png",sep="")
mediaKansai=calcMedia(type=type,year=year, region=region, depth=depth, 40,40)
imagePath<<-"../data/kansai.png"
plotMatrixModel(mediaKansai, saveFile, 40, 40)
region="Kanto"
saveFile = paste("./heatMap/",depth,'/',type,region,"_",depth,'_',year,".png",sep="")
mediaKanto=calcMedia(type=type,year=year, region=region, depth=depth, 45,45)
imagePath<<-"../data/kantomap.png"
plotMatrixModel(mediaKanto, saveFile, 45, 45)
year=year+1
}
}
plotModelsByYears('sc_ListaGA_New',100)
